# ğŸ•·ï¸ Apple Books Audiobook Scraper

Automatisches Crawling der Apple Books-Seite fÃ¼r Dirk Werner's Website, um die Audiobook-Whitelist aktuell zu halten.

## ğŸš€ Features

- **Automatisches Crawling** der Apple Books Author-Seite
- **Apple ID Extraktion** aus den Buch-Links
- **Vergleich mit bestehender Whitelist** fÃ¼r Ã„nderungsdetektion
- **Automatische Backup-Erstellung** vor Updates
- **Scheduler-System** fÃ¼r regelmÃ¤ÃŸige Updates
- **Detailliertes Logging** aller AktivitÃ¤ten

## ğŸ“‹ Voraussetzungen

- Node.js (Version 14 oder hÃ¶her)
- npm oder yarn
- Internetverbindung fÃ¼r Apple Books-Zugriff

## ğŸ› ï¸ Installation

1. **Dependencies installieren:**
```bash
npm install
```

2. **Erste AusfÃ¼hrung testen:**
```bash
npm run scrape
```

## ğŸ“– Verwendung

### Einmaliges Crawling
```bash
# Manuelles Crawling
npm run scrape

# Oder direkt
node appleBooksScraper.js
```

### Automatisierter Scheduler
```bash
# Scheduler starten (tÃ¤glich um 6:00 Uhr, wÃ¶chentlich am Sonntag um 8:00 Uhr)
node scheduler.js

# Test-Modus (jede Minute fÃ¼r Entwicklung)
node scheduler.js --test

# Sofortiges Crawling
node scheduler.js --run-now
```

### CLI-Optionen

| Option | Beschreibung |
|--------|-------------|
| `--test`, `-t` | Test-Modus: Crawling jede Minute |
| `--run-now`, `-r` | Sofortiges Crawling und Beenden |

## ğŸ“ Ausgabedateien

### Generierte Dateien
- `audiobooks_on_apple_by_dirkwerner_updated.js` - Neue Whitelist
- `scraper-logs.txt` - Log-Datei mit allen AktivitÃ¤ten
- `audiobooks_backup_YYYY-MM-DD.js` - Backup der alten Whitelist

### Dateistruktur
```
â”œâ”€â”€ appleBooksScraper.js      # Haupt-Scraper
â”œâ”€â”€ scheduler.js              # Automatisierter Scheduler
â”œâ”€â”€ package.json              # Dependencies
â”œâ”€â”€ audiobooks_on_apple_by_dirkwerner.js          # Aktuelle Whitelist
â”œâ”€â”€ audiobooks_on_apple_by_dirkwerner_updated.js  # Neue Whitelist
â”œâ”€â”€ scraper-logs.txt          # Log-Datei
â””â”€â”€ audiobooks_backup_*.js    # Backup-Dateien
```

## âš™ï¸ Konfiguration

### Scheduler-Zeiten anpassen
In `scheduler.js` kÃ¶nnen Sie die Crawling-Zeiten Ã¤ndern:

```javascript
const CONFIG = {
    // TÃ¤gliches Crawling um 6:00 Uhr
    dailySchedule: '0 6 * * *',
    
    // WÃ¶chentliches Crawling am Sonntag um 8:00 Uhr
    weeklySchedule: '0 8 * * 0',
    
    // Test-Schedule (jede Minute)
    testSchedule: '* * * * *'
};
```

### Cron-Syntax
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Minute (0-59)
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Stunde (0-23)
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€ Tag des Monats (1-31)
â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€ Monat (1-12)
â”‚ â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€ Wochentag (0-7, 0 und 7 = Sonntag)
â”‚ â”‚ â”‚ â”‚ â”‚
* * * * *
```

## ğŸ” Debugging

### Log-Datei prÃ¼fen
```bash
# Letzte 50 Zeilen der Log-Datei anzeigen
tail -50 scraper-logs.txt

# Log-Datei in Echtzeit verfolgen
tail -f scraper-logs.txt
```

### Manuelle Tests
```bash
# Test-Crawling mit detaillierter Ausgabe
node appleBooksScraper.js

# Scheduler im Test-Modus
node scheduler.js --test
```

## ğŸš¨ Fehlerbehebung

### HÃ¤ufige Probleme

1. **"ECONNREFUSED" oder "ETIMEDOUT"**
   - Internetverbindung prÃ¼fen
   - Apple Books-Seite manuell aufrufen
   - Proxy-Einstellungen prÃ¼fen

2. **"Keine Audiobooks gefunden"**
   - HTML-Struktur der Apple Books-Seite hat sich geÃ¤ndert
   - Selektoren in `appleBooksScraper.js` anpassen

3. **"Permission denied"**
   - Schreibrechte im Verzeichnis prÃ¼fen
   - Datei-Pfade Ã¼berprÃ¼fen

### Selektoren anpassen
Falls die Apple Books-Seite ihre HTML-Struktur Ã¤ndert, passen Sie die Selektoren in `appleBooksScraper.js` an:

```javascript
const selectors = [
    '.product-name',           // Standard Apple Books
    '.section__title',         // Alternative
    'h2',                      // Ãœberschriften
    'h3',                      // UnterÃ¼berschriften
    '.book-title',             // Buch-Titel
    '[data-testid="product-name"]', // Test-IDs
    '.product__title',         // Produkt-Titel
    '.audiobook-title'         // Audiobook-spezifisch
];
```

## ğŸ”„ Integration in Website

### Automatische Updates
1. Scheduler auf Server starten
2. Neue Whitelist wird automatisch generiert
3. Website lÃ¤dt aktualisierte Whitelist

### Manuelle Updates
1. Scraper ausfÃ¼hren
2. Neue Whitelist prÃ¼fen
3. Manuell in Website integrieren

## ğŸ“Š Monitoring

### Log-Analyse
```bash
# Erfolgreiche Crawlings zÃ¤hlen
grep "Crawling erfolgreich" scraper-logs.txt | wc -l

# Fehler in den letzten 24 Stunden
grep "$(date -d '1 day ago' +%Y-%m-%d)" scraper-logs.txt | grep "Fehler"
```

### Status-Check
```bash
# Letztes Update prÃ¼fen
grep "Whitelist aktualisiert" scraper-logs.txt | tail -1

# Anzahl gefundener Audiobooks
grep "Audiobooks gefunden" scraper-logs.txt | tail -1
```

## ğŸ¤ Beitragen

### Entwicklung
1. Fork erstellen
2. Feature-Branch erstellen
3. Ã„nderungen testen
4. Pull Request einreichen

### Bug Reports
- Log-Datei beifÃ¼gen
- Schritte zur Reproduktion beschreiben
- Erwartetes vs. tatsÃ¤chliches Verhalten

## ğŸ“„ Lizenz

MIT License - siehe LICENSE-Datei fÃ¼r Details.

## ğŸ†˜ Support

Bei Problemen oder Fragen:
1. Log-Datei prÃ¼fen
2. Debug-Modus aktivieren
3. Issue auf GitHub erstellen

---

**Entwickelt fÃ¼r Dirk Werner's Buchwebsite** ğŸ“š 